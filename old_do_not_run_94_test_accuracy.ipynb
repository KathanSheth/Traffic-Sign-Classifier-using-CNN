{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet Lab Solution\n",
    "![LeNet Architecture](lenet.png)\n",
    "Source: Yan LeCun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the MNIST data, which comes pre-loaded with TensorFlow.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = '/Users/kathan/udacity/Term-1/CarND-Term1-Starter-Kit/TensorFlow/CarND-Traffic-Sign-Classifier-Project/traffic-signs-data/train.p'\n",
    "validation_file='/Users/kathan/udacity/Term-1/CarND-Term1-Starter-Kit/TensorFlow/CarND-Traffic-Sign-Classifier-Project/traffic-signs-data/valid.p'\n",
    "testing_file = '/Users/kathan/udacity/Term-1/CarND-Term1-Starter-Kit/TensorFlow/CarND-Traffic-Sign-Classifier-Project/traffic-signs-data/test.p'\n",
    "\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data that TensorFlow pre-loads comes as 28x28x1 images.\n",
    "\n",
    "However, the LeNet architecture only accepts 32x32xC images, where C is the number of color channels.\n",
    "\n",
    "In order to reformat the MNIST data into a shape that LeNet will accept, we pad the data with two rows of zeros on the top and bottom, and two columns of zeros on the left and right (28+2+2 = 32).\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 32, 32, 3)\n",
      "(34799,)\n",
      "(12630, 32, 32, 3)\n",
      "(12630,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def normalize(data):\n",
    "    #data_mean = np.mean(data)\n",
    "    #data_std = np.std(data)\n",
    "    #new_data = (data - data_mean) / data_std\n",
    "    print (len(data))\n",
    "    new_data = np.array(data/255.0 - 0.5)\n",
    "    return new_data\n",
    "\n",
    "#def rgb2gray(data):\n",
    "    \n",
    "#    gray_images = np.zeros(shape=(len(data),32,32))\n",
    "#\n",
    "#\n",
    "#    for i in range(0,len(data)):\n",
    "#        gray_image[i] = cv2.cvtColor(data[i],cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "\n",
    "def rgb2gray(data):\n",
    "    gray = np.dot(data[...,:3],[0.299,0.587,0.114])\n",
    "    return gray\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data\n",
    "\n",
    "View a sample from the dataset.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzfYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118adb358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34799\n",
      "4410\n",
      "12630\n"
     ]
    }
   ],
   "source": [
    "#X_train_gray = np.zeros(shape=(len(X_train),32,32))\n",
    "#print (X_train.shape)\n",
    "X_train_gray = rgb2gray(X_train)\n",
    "X_valid_gray = rgb2gray(X_valid)\n",
    "X_test_gray = rgb2gray(X_test)\n",
    "\n",
    "X_train = normalize(X_train_gray)\n",
    "X_valid = normalize(X_valid_gray)\n",
    "X_test = normalize(X_test_gray)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.327240977328\n",
      "False\n",
      "(34799, 32, 32)\n",
      "(4410, 32, 32)\n",
      "(12630, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (X_train[0].mean())\n",
    "print ((X_train < -0.5).any())\n",
    "print (X_train.shape)\n",
    "print (X_valid.shape)\n",
    "print (X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 32, 32, 1)\n",
      "(4410, 32, 32, 1)\n",
      "(12630, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.reshape(X_train,[-1,32,32,1])\n",
    "X_valid = np.reshape(X_valid,[-1,32,32,1])\n",
    "X_test = np.reshape(X_test,[-1,32,32,1])\n",
    "print (X_train.shape)\n",
    "print (X_valid.shape)\n",
    "print (X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_norm = np.reshape(X_train_norm,[-1,32,32,1])\n",
    "#X_valid_norm = np.reshape(X_valid_norm,[-1,32,32,1])\n",
    "\n",
    "#print (X_train_norm.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "Shuffle the training data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "#X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "#p = np.random.permutation(len(X_train_norm))\n",
    "#X_train_norm,y_train = X_train_norm[p], y_train[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f2bf7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup TensorFlow\n",
    "The `EPOCH` and `BATCH_SIZE` values affect the training speed and model accuracy.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLUTION: Implement LeNet-5\n",
    "Implement the [LeNet-5](http://yann.lecun.com/exdb/lenet/) neural network architecture.\n",
    "\n",
    "This is the only cell you need to edit.\n",
    "### Input\n",
    "The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n",
    "\n",
    "### Architecture\n",
    "**Layer 1: Convolutional.** The output shape should be 28x28x6.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 14x14x6.\n",
    "\n",
    "**Layer 2: Convolutional.** The output shape should be 10x10x16.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 5x5x16.\n",
    "\n",
    "**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using `tf.contrib.layers.flatten`, which is already imported for you.\n",
    "\n",
    "**Layer 3: Fully Connected.** This should have 120 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 4: Fully Connected.** This should have 84 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 5: Fully Connected (Logits).** This should have 10 outputs.\n",
    "\n",
    "### Output\n",
    "Return the result of the 2nd fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # SOLUTION: Layer 1: Convolutional. Input = 32x32x3. Output = 16x16x16.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 16), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(16))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='SAME') + conv1_b\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 32x32x16. Output = 16x16x16.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # SOLUTION: Layer 2: Convolutional. Output = 8x8x32.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 16, 32), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(32))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='SAME') + conv2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 16x16x32. Output = 8x8x32.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    \n",
    "    # SOLUTION: Layer 3: Convolutional. Output = 4x4x64.\n",
    "    conv3_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 32, 64), mean = mu, stddev = sigma))\n",
    "    conv3_b = tf.Variable(tf.zeros(64))\n",
    "    conv3   = tf.nn.conv2d(conv2, conv3_W, strides=[1, 1, 1, 1], padding='SAME') + conv3_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 8x8x64. Output = 4x4x64.\n",
    "    conv3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # SOLUTION: Flatten. Input = 4x4x64. Output = 400.\n",
    "    fc0   = flatten(conv3)\n",
    "    \n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(1024, 800), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(800))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(800, 120), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(120))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2, keep_prob)\n",
    "\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 43.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(120, 43), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels\n",
    "Train LeNet to classify [MNIST](http://yann.lecun.com/exdb/mnist/) data.\n",
    "\n",
    "`x` is a placeholder for a batch of input images.\n",
    "`y` is a placeholder for a batch of output labels.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline\n",
    "Create a training pipeline that uses the model to classify MNIST data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 0.0007\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluate how well the loss and accuracy of the model for a given dataset.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y,keep_prob:1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Run the training data through the training pipeline to train the model.\n",
    "\n",
    "Before each epoch, shuffle the training set.\n",
    "\n",
    "After each epoch, measure the loss and accuracy of the validation set.\n",
    "\n",
    "Save the model after training.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.668\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.851\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.884\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.901\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.917\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.910\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.928\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.925\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.921\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "EPOCH 11 ...\n",
      "Validation Accuracy = 0.934\n",
      "\n",
      "EPOCH 12 ...\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "EPOCH 13 ...\n",
      "Validation Accuracy = 0.928\n",
      "\n",
      "EPOCH 14 ...\n",
      "Validation Accuracy = 0.937\n",
      "\n",
      "EPOCH 15 ...\n",
      "Validation Accuracy = 0.938\n",
      "\n",
      "EPOCH 16 ...\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "EPOCH 17 ...\n",
      "Validation Accuracy = 0.950\n",
      "\n",
      "EPOCH 18 ...\n",
      "Validation Accuracy = 0.936\n",
      "\n",
      "EPOCH 19 ...\n",
      "Validation Accuracy = 0.936\n",
      "\n",
      "EPOCH 20 ...\n",
      "Validation Accuracy = 0.944\n",
      "\n",
      "EPOCH 21 ...\n",
      "Validation Accuracy = 0.945\n",
      "\n",
      "EPOCH 22 ...\n",
      "Validation Accuracy = 0.944\n",
      "\n",
      "EPOCH 23 ...\n",
      "Validation Accuracy = 0.948\n",
      "\n",
      "EPOCH 24 ...\n",
      "Validation Accuracy = 0.939\n",
      "\n",
      "EPOCH 25 ...\n",
      "Validation Accuracy = 0.949\n",
      "\n",
      "EPOCH 26 ...\n",
      "Validation Accuracy = 0.944\n",
      "\n",
      "EPOCH 27 ...\n",
      "Validation Accuracy = 0.944\n",
      "\n",
      "EPOCH 28 ...\n",
      "Validation Accuracy = 0.937\n",
      "\n",
      "EPOCH 29 ...\n",
      "Validation Accuracy = 0.940\n",
      "\n",
      "EPOCH 30 ...\n",
      "Validation Accuracy = 0.934\n",
      "\n",
      "EPOCH 31 ...\n",
      "Validation Accuracy = 0.946\n",
      "\n",
      "EPOCH 32 ...\n",
      "Validation Accuracy = 0.949\n",
      "\n",
      "EPOCH 33 ...\n",
      "Validation Accuracy = 0.950\n",
      "\n",
      "EPOCH 34 ...\n",
      "Validation Accuracy = 0.946\n",
      "\n",
      "EPOCH 35 ...\n",
      "Validation Accuracy = 0.951\n",
      "\n",
      "EPOCH 36 ...\n",
      "Validation Accuracy = 0.946\n",
      "\n",
      "EPOCH 37 ...\n",
      "Validation Accuracy = 0.942\n",
      "\n",
      "EPOCH 38 ...\n",
      "Validation Accuracy = 0.938\n",
      "\n",
      "EPOCH 39 ...\n",
      "Validation Accuracy = 0.943\n",
      "\n",
      "EPOCH 40 ...\n",
      "Validation Accuracy = 0.945\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y,keep_prob:0.5})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_valid, y_valid)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "Once you are completely satisfied with your model, evaluate the performance of the model on the test set.\n",
    "\n",
    "Be sure to only do this once!\n",
    "\n",
    "If you were to measure the performance of your trained model on the test set, then improve your model, and then measure the performance of your model on the test set again, that would invalidate your test results. You wouldn't get a true measure of how well your model would perform against real data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.938\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYFBgYGBwkIBgcJBwYGCAsICQoKCgoKBggLDAsKDAkKCgr/2wBDAQICAgICAgUDAwUKBwYHCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgr/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDiNR8SNpWJwtsMIGt/s6FXOWYMvyovI5JyRu+9nqBQ09fE3iDxhovhnTbGysdQ8RyyJZ3uq3DxW8FrGrPcXUjDa4SKJFb5CpfDYyQUOxoUEOpm0hutNmCuW+zTNOdpOzMjYG5mXbhmDEEDABArA+K3w0TWW0nWfB8IEnh3UUluo2Cw+fHIy5VckKGHlZCcEh274WvhPDXDZBjeOcLQzuUVQfN8b9xz5JOnzpuK5XO102ot8qbs2eVxK8xoZJVq4JNzVtI/Fy8y5raPXlvaybWrWtjp5vDXifQvirrPwq1bUdIurrQbpVGo6eSYdStfm8uZGJZkfCMrrIzbGUr94EB03w+m17QluvtMSS9bmC4lUKkY5BQuo3Mq7snJHOcnBJy/DMEXhr4jeMvirrFpeJb+LPEd1NottFKRMbZ7qWQMwTcpOSoMec5GMHOR0h1KK0spbzRNctllt2keRZJrjy2y3yxsu1T1wdyrt55OGAPR4l0OHMDxnWoZO4uly03LktyKo6cXVUbSaSU76RbSlzJaJWnhr+0sRksamMTUm525vi5eZ8jd0ndx6tJtWb1PPdd0RNOgQQ3lrcyJDsur61vWbYzljsJZtr855U54XGMNu1/BvxB0Gzjs9Fj0pcfaY4BLeSLMXZpMmYPtARslTgDnjLEcV5vq3iqK2tbDVtUurRm1Kwtb1YofEWlQBUuEWRVeKS6VkwHGQVwrbgeRVG5+Onhn4eala69f6cLm2W5Hkw2etadeyq6NnJWC5ZlU7eGIAweDyBXy1LhbiBVFfCysn2X4Xkz6Xnou9pWud5qf7S/w/HjKXwnZaRLI0esvZJPp1pJskmMyhlZ1dMuQpU7VbgqdwJBbptZhsNatW1d72wjjsJvKj0yOWaQXDM+95FbBcg5K5yOBkk4JPgT/ALU3w3QTLa+GdVVJJpJVUwxlg7nczFjKeSxJ6f4VHpH7SWjS2stxF4fu2it42MuYolAHbGZeT7Ac812YvhjPKtVypYWaV3vbW70ej09CI1oRjZyTP//Z\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYFBgYGBwkIBgcJBwYGCAsICQoKCgoKBggLDAsKDAkKCgr/2wBDAQICAgICAgUDAwUKBwYHCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgr/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDY8MeFdav08vXNOtbT7OkXnpbJgwFVBaNJJOWG4csI1Zj3GABk/FTxl4f+Deh2muanp1zqU1xOIrGx06PY07NxKYy4YuwTLMxHGVXI8wNX0/rvhKD4eaDdeK/GWoW0Fva2rz3955xMcKICWJyeAAPxxXzTovi7X7T4b+O/+ClviAT2Mumadeaf8EtHbQl1B3aGKWW5vfsrSRrJ+4huWYlxsRJ2yfKTP1fGGd1cpwVPDYGqpYms9Ha/LFP3pvp2jFNat9lp2eGXCmW5nXxOeZ/Rf9m4JLmgpOLr1ppqlh4S3TlrOpKOsKUG95K/o3gaDSvFeg2PiDwqFutN1KAXEN8BwydhhiSDnjHYqQQMYrqbTw2Y0w0eD35J/U15T8GfiF4R8D65onjfwlo19pXwn+K88dzoNrqcSqfCutXEEdwbByjMggmjljliKsVAcDgrIa+m4/Cz8fLz9K+r4S4io51lvPP3a0Hy1I6aS7r+7L4ovzabvE+M8Q+DocMZrCeEk6mCxMfaYeo95QvZwn0VWjK9KrHpKMZJctSLPnj/AIKSfEHxD4l8U6D8BNG8AeMR4OuLiC78a634c0GW5ee335FvCcBGb5SxyQM7OcZFdP8AEf8Aba+BPi34QaV+z34L+H/xA8KeGnmtNP123uPBs8THRYx+9s4mjZtpmCJA7nkRSysDvC19Ay3d/Zlhp+txTJ38uYD/AOtUGleJ7rWfFOmeHdci+02t3qltHNFcYdGBmTGQcg4OD+FfjOPyXNMRj6mNeIvJ94p2jHaKfMtFr83c/cMNxvwq+FMHkWIyp8lDnd6eJnT56tR+9VnH2Uk5tKMVraMIqEbJu/zpqn7TP7LutfBLxP8As2+OLDxBqHg++u5P+EUgk0G5S50W1YLJHEjtGdwt5txgOBti8uIghCW6H9h79ojXfiF4Ok+Get6dd+INb8NReWdYaJ7c6jaBtsczCVc78YDZOScHucd94T+JevL4L0oiNyp0yD/lr1/drTL34oXyR/aJ1AQsAHL8ZJwBn68fWvQynLM5y7HrF0q0VdWaUWuaO+t5NaPVO11r3Z4uc8RcKZlwtUyVYKqo86qQc68Z+zqJcspRXsIySnD3ZxUkpWg2rwTP/9k=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import Image,display\n",
    "\n",
    "import os\n",
    "directory = '/Users/kathan/udacity/Term-1/CarND-Term1-Starter-Kit/TensorFlow/CarND-Traffic-Sign-Classifier-Project/five-images'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"): \n",
    "        input_path = os.path.join(directory, filename)\n",
    "        img = cv2.imread(input_path)\n",
    "        #print (img)\n",
    "        display(Image(input_path))\n",
    "        data = np.array([mpimg.imread(os.path.join(directory, name)) for name in os.listdir(directory)], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 254.  255.  255.]\n",
      "  [ 255.  255.  253.]\n",
      "  [ 255.  255.  251.]\n",
      "  ..., \n",
      "  [ 251.  251.  255.]\n",
      "  [ 251.  255.  255.]\n",
      "  [ 247.  255.  246.]]\n",
      "\n",
      " [[ 250.  252.  255.]\n",
      "  [ 255.  253.  255.]\n",
      "  [ 255.  255.  253.]\n",
      "  ..., \n",
      "  [ 166.  179.  223.]\n",
      "  [ 221.  237.  250.]\n",
      "  [ 247.  255.  244.]]\n",
      "\n",
      " [[ 254.  252.  255.]\n",
      "  [ 255.  254.  255.]\n",
      "  [ 255.  254.  250.]\n",
      "  ..., \n",
      "  [ 100.  124.  198.]\n",
      "  [ 199.  216.  246.]\n",
      "  [ 248.  255.  244.]]\n",
      "\n",
      " ..., \n",
      " [[ 255.  251.  250.]\n",
      "  [ 255.  250.  252.]\n",
      "  [ 254.  255.  255.]\n",
      "  ..., \n",
      "  [ 207.  198.  183.]\n",
      "  [ 241.  242.  228.]\n",
      "  [ 247.  255.  241.]]\n",
      "\n",
      " [[ 255.  250.  248.]\n",
      "  [ 255.  255.  253.]\n",
      "  [ 249.  255.  255.]\n",
      "  ..., \n",
      "  [ 255.  255.  253.]\n",
      "  [ 254.  253.  251.]\n",
      "  [ 255.  255.  250.]]\n",
      "\n",
      " [[ 255.  254.  255.]\n",
      "  [ 248.  255.  251.]\n",
      "  [ 241.  255.  247.]\n",
      "  ..., \n",
      "  [ 248.  255.  255.]\n",
      "  [ 251.  249.  255.]\n",
      "  [ 255.  247.  255.]]]\n"
     ]
    }
   ],
   "source": [
    "print (data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32, 32, 3)\n",
      "(5, 32, 32)\n",
      "5\n",
      "(5, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "#X_train_gray = np.zeros(shape=(len(X_train),32,32))\n",
    "#print (X_train.shape)\n",
    "test_data_gray1 = rgb2gray(data)\n",
    "\n",
    "\n",
    "print (data.shape)\n",
    "print (test_data_gray1.shape)\n",
    "\n",
    "test_data = normalize(test_data_gray1)\n",
    "test_data = np.reshape(test_data,[-1,32,32,1])\n",
    "#test_data_final = np.concatenate((data, test_data_gray), axis=3)\n",
    "\n",
    "#print (test_data_final.shape)\n",
    "\n",
    "#test_data = test_data_final\n",
    "\n",
    "\n",
    "\n",
    "print(test_data.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "My Data Set Accuracy = 0.400\n"
     ]
    }
   ],
   "source": [
    "my_labels = np.array([35,38,27,1,14])\n",
    "print (my_labels.shape)\n",
    "with tf.Session() as sess:\n",
    "    #saver.restore(sess, \"./lenet\")\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    #preditction = sess.run(logits,feed_dict={x:test_data,keep_prob:1.0})\n",
    "    #print(prediction)\n",
    "    my_accuracy = evaluate(test_data, my_labels)\n",
    "    print(\"My Data Set Accuracy = {:.3f}\".format(my_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
